{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba2421a6",
   "metadata": {},
   "source": [
    "# **I &nbsp;&nbsp;&nbsp; Khai báo thư viện**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfde1d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data.dataset import PhoMTDataset\n",
    "from services.models.tokenizer.tokenizer import Tokenizer\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from services.machine_translator import MachineTranslator, MachineTranslatorConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3124d7",
   "metadata": {},
   "source": [
    "# **II &nbsp;&nbsp;&nbsp; Bộ dữ liệu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac6152fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PhoMTDataset(\"en-vi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82befff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30000\n",
    "train_size = int(0.8 * N)\n",
    "test_size = int(0.1 * N)\n",
    "dev_size = int(0.1 * N)\n",
    "\n",
    "train_set = {\n",
    "    \"source\": dataset.train()[\"source\"][:train_size],\n",
    "    \"target\": dataset.train()[\"target\"][:train_size]\n",
    "}\n",
    "test_set = {\n",
    "    \"source\": dataset.test()[\"source\"][:test_size],\n",
    "    \"target\": dataset.test()[\"target\"][:test_size]\n",
    "}\n",
    "dev_set = {\n",
    "    \"source\": dataset.dev()[\"source\"][:dev_size],\n",
    "    \"target\": dataset.dev()[\"target\"][:dev_size]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b99bc72",
   "metadata": {},
   "source": [
    "# **III &nbsp;&nbsp;&nbsp; Mã hóa dữ liệu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa2ba77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(\"en-vi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a8684c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 192\n",
    "train_data = tokenizer.tokenize(train_set, max_seq_length)\n",
    "test_data = tokenizer.tokenize(test_set, max_seq_length)\n",
    "dev_data = tokenizer.tokenize(dev_set, max_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ab98f3",
   "metadata": {},
   "source": [
    "# **IV &nbsp;&nbsp;&nbsp; Mô hình**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e6874d",
   "metadata": {},
   "source": [
    "## **1 &nbsp;&nbsp;&nbsp; Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ec68d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng tham số: 37.14M\n"
     ]
    }
   ],
   "source": [
    "# block_size: int = 192\n",
    "# vocab_size: int = 32000\n",
    "# n_layer: int = 6\n",
    "# n_head: int = 6\n",
    "# n_embd: int = 384\n",
    "# dropout: float = 0.2\n",
    "# bias: bool = True\n",
    "# Nhóm thực hiện thực nghiệm bằng cách tinh chỉnh các tham số trên bằng phương pháp thủ công\n",
    "\n",
    "config = MachineTranslatorConfig()\n",
    "translator = MachineTranslator(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "341ff58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(translator.parameters(), lr=3e-4, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ccf5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else dev_data\n",
    "    ix = torch.randint(0, len(data[\"source\"]), (batch_size, ))\n",
    "    x = torch.stack([data[\"source\"][i] for i in ix])\n",
    "    y = torch.stack([data[\"target\"][i] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31002afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_epochs = 20\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    \n",
    "    translator.eval()\n",
    "    for split in [\"train\", \"dev\"]:\n",
    "        losses = torch.zeros(eval_epochs)\n",
    "        \n",
    "        for k in range(eval_epochs):\n",
    "            X, y = get_batch(split)\n",
    "            _, loss = translator(X, y[:, :-1], y[:, 1:])\n",
    "                \n",
    "            losses[k] = loss.item()\n",
    "            \n",
    "        out[split] = losses.mean()\n",
    "    translator.train()\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22527fa3",
   "metadata": {},
   "source": [
    "## **2 &nbsp;&nbsp;&nbsp; Huấn luyện mô hình**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "eval_interval = 500\n",
    "train_losses = []\n",
    "dev_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccfa6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    if epoch % eval_interval == 0 or epoch == epochs - 1:\n",
    "        losses = estimate_loss()\n",
    "        train_losses.append(losses[\"train\"].item())\n",
    "        dev_losses.append(losses[\"dev\"].item())\n",
    "        print(f\"step {epoch}: train loss {losses['train']:.4f}, dev loss {losses['dev']:.4f}\")\n",
    "        \n",
    "    X_b, y_b = get_batch(\"train\")\n",
    "            \n",
    "    logits, loss = translator(X_b, y_b[:, :-1], y_b[:, 1:])\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc38625",
   "metadata": {},
   "source": [
    "## **3 &nbsp;&nbsp;&nbsp; Đánh giá mô hình**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab6e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đồ thị mất mát của mô hình\n",
    "steps = [0] + list(range(0, epochs, eval_interval))\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plt.plot(steps, losses[\"train\"], linewidth=1.5, label=\"Train Loss\")\n",
    "plt.plot(steps, losses[\"dev\"], linewidth=1.5, label=\"Validation Loss\")\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bda875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chỉ số Perplexity trên tập test\n",
    "translator.eval()\n",
    "@torch.no_grad\n",
    "def test_loss():\n",
    "    losses = []\n",
    "    for i in range(0, len(test_data[\"source\"]), batch_size):\n",
    "        x = test_data[\"source\"][i:i+batch_size]\n",
    "        y = test_data[\"target\"][i:i+batch_size]\n",
    "        _, loss = translator(x, y[:, :-1], y[:, 1:])\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return torch.tensor(losses, dtype=torch.float32).mean()\n",
    "\n",
    "ppl = math.exp(test_loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673664a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chỉ số BLEU trên tập test\n",
    "@torch.no_grad\n",
    "def bleu_score_corpus(references, hypotheses):\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    refs = [[r.lower().split()] for r in references]\n",
    "    hypos = [h.lower().split() for h in hypotheses]\n",
    "    return corpus_bleu(\n",
    "        refs,\n",
    "        hypos,\n",
    "        weights=(0.25, 0.25, 0.25, 0.25),\n",
    "        smoothing_function=smoothie\n",
    "    )\n",
    "    \n",
    "hypotheses = [translator.translate(t, max_seq_length) for t in test_set[\"source\"]]\n",
    "print(bleu_score_corpus(test_data[\"target\"], hypotheses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d984043",
   "metadata": {},
   "source": [
    "## **4 &nbsp;&nbsp;&nbsp; Lưu trọng số mô hình**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695de769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(translator.state_dict(), \"services/translator_weights/weights.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
